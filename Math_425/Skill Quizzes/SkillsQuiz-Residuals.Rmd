---
title: "Skills Quiz: Residuals, Sums of Squares, and R-squared"
output: 
  html_document:
    theme: cerulean
    code_folding: hide
    toc: true
    toc_float: true
---


## Instructions

Use this file to keep a record of your work as you complete the "Skills Quiz: Residuals, Sums of Squares, and R-squared" assignment in Canvas.


----

<!-- Note: The {} after each Problem and Part header allows you to keep track of what work you have completed. Write something like {Done} once you complete each problem and your html file will then show you a nice summary of what you have "done" already. -->

## Problem 1 {Done}

Open the `Orange` dataset in R. As stated in the help file for this data set, "The Orange data... records of the growth of orange trees." 

Perform a simple linear regression of the circumference of the tree based on its age in days.

```{r Overview for Orange, message=FALSE, warning=FALSE}
# Perform the Test
#View(Orange)
mylm <- lm(circumference ~ age, data = Orange)
summary(mylm)


# Check Assumptions
par(mfrow=c(1,3))
plot(mylm, which=1:2)
plot(mylm$residuals, type = "b", main = "Residuals vs Order")
#plot(mylm, which = 1)
# qqPlot(mylm$residuals, main = "Q-Q Plot of Residuals", id = FALSE)

#Plot the Regression Line
plot(circumference ~ age, data = Orange)
abline(mylm)
```

### Part (a) {Done}

Type out the mathematical equation for this regression model and label both $Y$ and $X$ in the equation.

<div class="YourAnswer">

$$
  \underbrace{Y_i}_\text{Tree's Circumference} = \overbrace{{\underbrace{\beta_0}_\text{Intercept} + \underbrace {\beta_1}_\text{Slope}}\underbrace{X_i}_\text{Age}}^\text{True Regression Line} + \epsilon_i \quad \text{where} \ \epsilon_i \sim N(0, \sigma^2)
$$

</div>


### Part (b) {Done}
 
Plot a scatterplot of the data with your regression line overlaid.

<div class="YourAnswer">

```{r Scatterplot for Orange, message=FALSE, warning=FALSE}
# Plot a scatterplot
plot(circumference ~ age, 
     data = Orange,
     col="orange",
     pch=16,
     main = "Growth of Orange Trees \n (Orange data set)",
     ylab= "Circumference of Trees in mm (circumference)",
     xlab= "Age of Trees in Days (age)")
abline(mylm,
       col="firebrick")
```

</div>


### Part (c) {Done}

State and interpret the slope and y-intercept of this regression. Are they meaningful for this data?

<div class="YourAnswer">

The slope is $0.106770$ with a $p$-value of **1.93e-14**. This has great significance to use. However, the y-intercept, $17.399650$, has a $p$-value of **0.0518**.

</div> 
 
 
### Part (d) {Done}

What are the values of SSE, SSR, SSTO, $R^2$, and the correlation $r$ for this regression?
 
<div class="YourAnswer">

```{r Values for Orange, message=FALSE, warning=FALSE}
# SSE
sum(mylm$res^2)

# SSR
sum( (mylm$fit - mean(Orange$circumference))^2 )
SSR <- sum( (mylm$fit - mean(Orange$circumference))^2 )

# SSTO
sum( (Orange$circumference - mean(Orange$circumference))^2 )
SSTO <- sum( (Orange$circumference - mean(Orange$circumference))^2 )

# R^2
SSR/SSTO

# r
cor(Orange$age, Orange$circumference)
```

</div>


### Part (e) {Done}

How do the values of SSR and SSTO relate to the correlation?

<div class="YourAnswer">

When I divide SSR by SSTO, I will get $R^2$. If I then square root $R^2$, I will be able to get the value of the correlation.

</div>


### Part (f) {Done}

What circumference would we expect orange trees to have on average after 3 years, based on this regression? 

<div class="YourAnswer">

```{r Circumference of Three Years, message=FALSE, warning=FALSE}
17.399650 + 0.106770*(3*365)
```


</div>



----

## Problem 2 {Done}

Open the **mtcars** dataset in R. Fit three different regression models to the data that can each be used to explain average gas mileage of a vehicle (`mpg`). 

* The first regression should use the weight (`wt`) of the vehicle as the explanatory variable.
* The second should use the number of cylinders (`cyl`) of the engine of the vehicle as the explanatory variable.
* The third should use the gross horsepower of the vehicle (`hp`) as the explanatory variable.

```{r Linear Models for Three, message=FALSE, warning=FALSE}
# Perform the Test

wt.lm <- lm(mpg ~ wt, data = mtcars)
summary(wt.lm)

cyl.lm <- lm(mpg ~ cyl, data = mtcars)
summary(cyl.lm)

hp.lm <- lm(mpg ~ hp, data = mtcars)
summary(hp.lm)

```



### Part (a) {Done}

Plot all three regressions in three separate plots.

<div class="YourAnswer">

```{r Three Scatterplots, message=FALSE, warning=FALSE}
par(mfrow=c(1,3))

plot(mpg ~ wt, data = mtcars)
abline(wt.lm)

plot(mpg ~ cyl, data = mtcars)
abline(cyl.lm)

plot(mpg ~ hp, data = mtcars)
abline(hp.lm)

```

</div>


### Part (b) {Done}

State the values of SSE, SSR, SSTO, and $R^2$ for each regression. 

<div class="YourAnswer">

```{r Values for wt.lm, message=FALSE, warning=FALSE}

# plot(mpg ~ wt, data = mtcars)
# abline(wt.lm)


# SSE
sum( (mtcars$mpg - wt.lm$fit)^2)

# SSR
sum( (wt.lm$fit - mean(mtcars$mpg))^2 )


# SSTO
sum( (mtcars$mpg - mean(mtcars$mpg))^2 )


# R^2
SSR <- sum( (wt.lm$fit - mean(mtcars$mpg))^2 )
SSTO <- sum( (mtcars$mpg - mean(mtcars$mpg))^2 )
SSR/SSTO

# r
cor(mtcars$wt, mtcars$mpg)
```



```{r Values for cyl.lm, message=FALSE, warning=FALSE}
# plot(mpg ~ cyl, data = mtcars)
# abline(cyl.lm)


# SSE
sum( (mtcars$mpg - cyl.lm$fit)^2)

# SSR
sum( (cyl.lm$fit - mean(mtcars$mpg))^2 )


# SSTO
sum( (mtcars$mpg - mean(mtcars$mpg))^2 )


# R^2
SSR <- sum( (cyl.lm$fit - mean(mtcars$mpg))^2 )
SSTO <- sum( (mtcars$mpg - mean(mtcars$mpg))^2 )
SSR/SSTO

# r
cor(mtcars$cyl, mtcars$mpg)
```



```{r Values for hp.lm, message=FALSE, warning=FALSE}
# plot(mpg ~ hp, data = mtcars)
# abline(hp.lm)

# SSE
sum( (mtcars$mpg - hp.lm$fit)^2)

# SSR
sum( (hp.lm$fit - mean(mtcars$mpg))^2 )


# SSTO
sum( (mtcars$mpg - mean(mtcars$mpg))^2 )


# R^2
SSR <- sum( (hp.lm$fit - mean(mtcars$mpg))^2 )
SSTO <- sum( (mtcars$mpg - mean(mtcars$mpg))^2 )
SSR/SSTO

# r
cor(mtcars$hp, mtcars$mpg)
```


</div>


### Part (c) {Done}

Compare the values from **Part (b)** across each regression. Consider these questions as you compare these numbers.

* What insight do these numbers give about the regression?
* Which numbers change, which stay the same, in these regressions? Why?
* Which regression is best at explaining average `mpg` according to these numbers?

<div class="YourAnswer">

* What insight do these numbers give about the regression?

    The closer they are to 1 the better my regression line and the data points line up with one another.

* Which numbers change, which stay the same, in these regressions? Why?

    All of the number change except for the SSTO value because it's the same information for all three. I'm taking the Y variable and subtracting the mean of the Y variable squared from it.

* Which regression is best at explaining average `mpg` according to these numbers?

    The weight variable is the best at explaining the average mpg with an $R^2$ value of 0.7.

</div> 
 
 



----

Before we can really trust the $R^2$ value from a regression model, there are important diagnostic checks to perform on the regression. 

You now have a better understanding of what a **residual** and a **fitted-value** are in regression. With that improved knowledge, work through the following problem.



----

## Problem 3 {Talk with Saunders}

Check the following technical details for each of the three regressions of **Problem 2**.

### Part (a) {Done}

Create a (1) residuals vs. fitted-values plot, (2) Q-Q Plot of the residuals, and (3) residuals vs. order plot for each regression of **Problem 2**.

<div class="YourAnswer">

```{r Diagnostics for wt.lm, message=FALSE, warning=FALSE}
par(mfrow=c(1,3))
plot(wt.lm, which=1:2)
plot(wt.lm$residuals, main = "Residuals vs Order")
```

```{r Diagnostics for cyl.lm, message=FALSE, warning=FALSE}
par(mfrow=c(1,3))
plot(cyl.lm, which=1:2)
plot(cyl.lm$residuals, main = "Residuals vs Order")
```

```{r Diagnostics for hp.lm, message=FALSE, warning=FALSE}
par(mfrow=c(1,3))
plot(hp.lm, which=1:2)
plot(hp.lm$residuals, main = "Residuals vs Order")
```

</div>


### Part (b) {Talk with Saunders}

Explain, as best you understand currently, what each of these three plots show for these regressions.

<div class="YourAnswer">

The plots for the Weight Linear Model show that the relation between the Y and X variable are not linear.  

The plots for the Cylindar Linear Model look like both the relation between the Y and X variable are not linear *and* that the variance between the error terms are not constant.  

The plots for the Horsepower Linear Model appear to be normal.

</div>


### Part (c) {Talk with Saunders}

Comment on whether or not we should trust the $R^2$ value from each of your three regressions based on your plots in Part (a). 

<div class="YourAnswer">

We should probably not trust the $R^2$ values with the weight and cylinder linear models. The Horsepower linear model appears to be trustable.

</div>



----











<style>

.YourAnswer {
  color: #317eac;
  padding: 10px;
  border-style: solid;
  border-width: 2px;
  border-color: skyblue4;
  border-radius: 5px;
}

</style>

 
 